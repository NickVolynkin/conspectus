# Машинное обучение для предсказания продаж интернет-магазина Ozon.ru

**Александр Алексейцев**. Лид дата сайенс в Ozon.ru.

Расскажу про потоварное предсказание спроса.
Стали пытаться примениить модели не только для предсказания спроса, но и для решения других задач.

Доклад - продолжение доклада с Highload 2018: http://www.highload.ru/moscow/2018/abstracts/4344 

С тех пор прошел почти год, много нового сделали. 

- В первую очередь, сделали исследование по сезонным паттернам поиска товаров, группы сезонных товаров нужно прогнозировать по-разному. Мы научились это делать. 
- Новые фичи кросс-товарного взаимодействия.
- Продвинулись в применении моделей для ценоообразования.
- Решили сделать ручной анализ данных.

## Зачем нужно прогнозировать продажи

Чтобы планировать складские мощности, пополнять запасы, не допустить завалов, знать тренды. 
Хотим потоварно прогнозировать спрос на 1,5 миллиона товаров на максимально возможный без потери точности горизонт. 
Почему не скользящее среднее? Потому, что наш прогноз точнее. 

MAE стал выше, да, рынок e-commerce растет, мир меняется, данные устаревают быстрее. Данные за 10 лет никому не нужны, они не дают прироста в качестве. 

3,6 MAE. 
Попробовали линейную регресию. Перепробовали множество моделей, бустинг, на нем и остановились. В частности, на LightGBM. 

Выбираем для каждого товара его покупки за случайные 7 моментов времени и фичи (показатели), информация о прошлых продажах, сколько продали в категории за прошлую неделю, за месяц, год, данные ценах конкурентов. 
Доступность. 

Остановлюсь на двух новых вещах. 

## Сезонность

У многих товаров есть повторяющийся из года в год паттерн. Но вручную разметить это нереально. 
Как научить машину понимать сезонность. 
Нужно минимум два года истории, на Ozon каждый день появляется 1000 новинок. Раньше их размечал человек. 

Взяли товары с двухлетней историей, взяли времененные ряды продаж и кластеризовали, вышло 8-9 кластеров. Так мы разметили хотя бы часть товаров. Кластеры очень хорошо интерпретируемы - новый год, 1 сентября, лето. 
Выделили из этих товаров фичи, для которых не нужны данные о сезонности. 

Обучили классификатор на полученной разметке, он работает на новых товарах. 

### Кластеризация 

Заполнили пропуски во временных рядах, не более месяца подряд пропуск. 
применили standard scaler. 

Попробовали подход применить функцию близости, не получилось.
А потом подсмотрели в одной статье, что кластеризовать временные ряды в пространстве фич. 
Добавили фактор отношения продаж вокруг важных дат (НГ, 8 марта). 

### Классификация

Выделили признаки товаров, для которых не нужны двухлетние данные. 
См. статью на Хабр: https://habr.com/ru/company/ozontech/blog/432760/ 

- **Процент ошибки прогноза продаж снизился на 10 процентов**.
- **Отдел продаж - меньше ручной работы**.
- **Не закупаем сезонные товары после точки, когда они не нужны**.

## Предсказание цен

Написали функцию. 
Отдел продаж говорит - нам нужно такой-то процент от маржи, а нижняя ограничение - цена не отрицательная и не миллион долларов. Произведение цены товара на прогноз продаж при такой цене. 

Посчитали прогнозы продаж товара по определенной цене. Применили эвристику, чтобы выявить рабочий диапазон кривой, **за пределами этого диапазона доверять нашей модели нельзя**.

Для десятков тысяч товаров модель работает несколько часов. 
Мы исходили из предположения, что цена одного товара не влияет на продажи другого. 

Оптимизатор может предложить как повысить (если это не повлияет на продажи), так и понизить цену (если это резко их поднимет). Одно отвечает за спрос, другое - за маржу. 

*Почему не в проде?* Потому, что обучено на 20 000 товаров, а как это повлияет на остальные, вне выборки? 

Мы начали добавлять кросс-товарные фичи: цена и доступность схожего товара. Берем 10 ближайших соседей. 
Feature importance высокая, но работает только локально. 

Совет: изучите свою выборку. Мы обнаружили, что в разные моменты времени концентрация разных типов сэмплов может сильно отличаться. Например, процентов 10 сэмплов равно 0, а потом в какой-то момент времени 90 процентов. Из-за рандомной выборки по времени. 

## Планы

- Добить кросс-товарные взаимодействия товаров.
- Перейти от бустинга к нейросетям.
- Нужно улучшать способность к экстраполяции, хотим сделать комбинированную модель с товарными и категориальными фичами.
- Оцифровка маркетинговых механик. 
- Новые фичи (погода, google analytics, тренды). 

## Вопросы

Вопрос: А нет ли у вас аномалии, что недопрогноз дает точность в последующем? 
Ответ: Когда собираем выборку, мы берем только те семплы, когда товар всю таргет неделю присутствовал на складе. 

Вопрос: С учетом того, что у вас много фичей прошлых отрезков, нет ли проблемы запаздывающего прогноза. Как интерпретируете прозноз для бизнеса?  
Ответ: Да, бизнес не всегда понимает, мы стали пользоваться встроенными в lightgbm возможностями, чтобы показать вес каждой фичи в прогнозе, потом построили линейную регресию, отношения одной цены к другой, умноженное на продажи. Пока что общение с бизнесом в процесса налаживания, не договорились, как интерпретировать результаты. 

По первому вопросу, нет, у нас таких проблем нет, мы давно не на линейной регресии. 

Вопрос: Как вам кажется развиваться, чтобы избежать канибализации? И как вы взаимодействуете с продажами конкурентов? 
Ответ: От анализа влияния продаж конкурентов мы очень далеки. От покупки данных в том числе. Хотим понять канибализацию внутри нашей компании. Мы нашли пример суперзаменяемого товара - игла для накачивания мяча, бренд не важен никому. Как только цена одной падает на 10 рублей, все остальные никому не нужны.  

